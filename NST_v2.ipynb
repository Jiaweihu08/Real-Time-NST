{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NST v2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jiaweihu08/Real-Time-NST/blob/master/NST_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6bHgyKrMh-H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install --upgrade tensorflow==2.0.0.-rc1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3ayDOm0MrNc",
        "colab_type": "code",
        "outputId": "13e85eb5-c932-460a-b0fa-6b9d01ad58fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.python.keras.preprocessing import image as kp_image\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from IPython import display\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0-rc1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmcKKJZ5_FYC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def load_image(img_path):\n",
        "\n",
        "    img = Image.open(img_path)\n",
        "    \n",
        "    img = img.resize((288, 288), Image.ANTIALIAS)\n",
        "    \n",
        "    img = kp_image.img_to_array(img)\n",
        "    \n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    \n",
        "    return img\n",
        "\n",
        "def tensor_to_image(tensor):\n",
        "  #tensor = tensor*255\n",
        "  tensor = np.array(tensor)\n",
        "\n",
        "  if np.ndim(tensor)>3:\n",
        "    assert tensor.shape[0] == 1\n",
        "    tensor = tensor[0]\n",
        "\n",
        "  return Image.fromarray(tensor)\n",
        "\n",
        "def imshow(img, title=None):\n",
        "    \"\"\"Function used to display the image.\n",
        "\n",
        "    We use matplitlib.pyplot.imshow to visualize the image,\n",
        "    and when it takes an image in array form, the size of it should be\n",
        "    (M, N, 3) for RGB images with values(0-1 float, 0-255 int),\n",
        "    so in this case we\n",
        "    need to convert the values of the array from float to int.\n",
        "    \n",
        "    \"\"\"\n",
        "    # Removing the batch dimension\n",
        "    out = np.squeeze(img, axis=0)\n",
        "    # Convert float to int\n",
        "    out = out.astype('uint8')\n",
        "    plt.imshow(out)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.imshow(out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7q78b2FNQdI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model():\n",
        "    vgg = keras.applications.vgg19.VGG19(weights='imagenet', include_top=False)\n",
        "    vgg.trainable = False\n",
        "\n",
        "    style_output = [vgg.get_layer(name).output for name in style_layers]\n",
        "    content_output = [vgg.get_layer(name).output for name in content_layers]\n",
        "\n",
        "    model_output = style_output + content_output\n",
        "\n",
        "    return keras.Model(vgg.input, model_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8eVAyfGQXL9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gram_matrix(style_outputs):\n",
        "    channels = int(style_outputs.shape[-1])\n",
        "    style_outputs = tf.reshape(style_outputs, [-1, channels])\n",
        "    n = tf.shape(style_outputs)[0]\n",
        "    \n",
        "    gram = tf.matmul(style_outputs, style_outputs, transpose_a=True)\n",
        "\n",
        "    return gram / tf.cast(n, tf.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjlTNP3AMujW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class StyleContentModel(keras.models.Model):\n",
        "    def __init__(self, style_layers, content_layers):\n",
        "        super().__init__()\n",
        "        self.vgg = get_model()\n",
        "        self.style_layers = style_layers\n",
        "        self.content_layers = content_layers\n",
        "        self.num_style_layers = len(style_layers)\n",
        "        self.vgg.trainable = False\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        #inputs = inputs * 255.0\n",
        "        preprocessed_inputs = keras.applications.vgg19.preprocess_input(inputs)\n",
        "        outputs = self.vgg(preprocessed_inputs)\n",
        "        style_outputs, content_outputs = (outputs[:num_style_layers],\n",
        "                                          outputs[num_style_layers:])\n",
        "        style_outputs = [gram_matrix(style_output)\n",
        "                        for style_output in style_outputs]\n",
        "        \n",
        "        style_dict = {style_name: value\n",
        "                      for style_name, value in \n",
        "                      zip(self.style_layers, style_outputs)}\n",
        "       \n",
        "        content_dict = {content_name: value\n",
        "                        for content_name, value in\n",
        "                        zip (content_layers, content_outputs)}\n",
        "        \n",
        "        return {'style': style_dict, 'content': content_dict}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIprmbqf1iqb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def style_content_loss(outputs):\n",
        "    style_outputs = outputs['style']\n",
        "    content_outputs = outputs['content']\n",
        "\n",
        "    style_loss = tf.add_n([tf.reduce_mean(tf.square(style_outputs[name], style_target[name]))\n",
        "                                          for name in style_outputs.keys()])\n",
        "    style_loss *= style_weight / num_style_layers\n",
        "\n",
        "    content_loss = tf.add_n([tf.reduce_mean(tf.square(content_outputs[name], content_target[name]))\n",
        "                                          for name in content_outputs.keys()])\n",
        "    style_loss *= content_weight / num_content_layers\n",
        "\n",
        "    loss = style_loss + content_loss\n",
        "\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Uii0QSq248f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyInstanceNorm(keras.layers.Layer):\n",
        "    def build(self, batch_input_shape):\n",
        "        self.scale = self.add_weight(name='scale', shape=[batch_input_shape[-1]],\n",
        "                                     initializer='ones', dtype=tf.float32)\n",
        "        self.shift = self.add_weight(name='shift', shape=[batch_input_shape[-1]],\n",
        "                                     initializer='zeros', dtype=tf.float32)\n",
        "        super().build(batch_input_shape)\n",
        "    \n",
        "    def call(self, X, training=True):\n",
        "        if training:\n",
        "            mean, variance = tf.nn.moments(X, axes=[1,2], keepdims=True)\n",
        "            std = tf.sqrt(variance)\n",
        "            epsilon = 1e-3\n",
        "            X_ = (X - mean) / (std + epsilon)\n",
        "            return self.scale * X + self.shift\n",
        "        else:\n",
        "            return X\n",
        "\n",
        "def conv_layer(net, filters, kernel_size, strides,\n",
        "               padding='SAME', relu=True,\n",
        "               transpose=False, input_shape=None):\n",
        "    if not transpose:\n",
        "        if input_shape:\n",
        "            x = keras.layers.Conv2D(filters=filters, kernel_size=kernel_size,\n",
        "                                    strides=strides, padding=padding,\n",
        "                                    input_shape=input_shape,\n",
        "                                    kernel_initializer=keras.initializers.TruncatedNormal(0, 1, 1))(net)\n",
        "        else:\n",
        "            x = keras.layers.Conv2D(filters=filters, kernel_size=kernel_size,\n",
        "                                    strides=strides, padding=padding,\n",
        "                                    kernel_initializer=keras.initializers.TruncatedNormal(0, 1, 1))(net)\n",
        "    else:\n",
        "        x = keras.layers.Conv2DTranspose(filters=filters, kernel_size=kernel_size,\n",
        "                                         strides=strides, padding=padding,\n",
        "                                         kernel_initializer=keras.initializers.TruncatedNormal(0, 1, 1))(net)\n",
        "    \n",
        "    x = MyInstanceNorm()(x)\n",
        "    \n",
        "    if relu:\n",
        "        x = keras.activations.relu(x)\n",
        "    \n",
        "    return x\n",
        "\n",
        "def residual_block(net):\n",
        "    tmp1 = conv_layer(net, 128, 3, 1)\n",
        "    \n",
        "    return net + conv_layer(tmp1, 128, 3, 1, relu=False)\n",
        "\n",
        "def NST_model(init_image):\n",
        "    conv1 = conv_layer(init_image, 32, 9, 1)\n",
        "    conv2 = conv_layer(conv1, 64, 3, 2)\n",
        "    conv3 = conv_layer(conv2, 128, 3, 2)\n",
        "    resid1 = residual_block(conv3)\n",
        "    resid2 = residual_block(resid1)\n",
        "    resid3 = residual_block(resid2)\n",
        "    resid4 = residual_block(resid3)\n",
        "    resid5 = residual_block(resid4)\n",
        "    conv_t1 = conv_layer(resid2, 64, 3, 2, transpose=True)\n",
        "    conv_t2 = conv_layer(conv_t1, 32, 3, 2, transpose=True)\n",
        "    conv_t3 = conv_layer(conv_t2, 3, 9, 1, relu=False)\n",
        "    out = keras.activations.sigmoid(conv_t3) * 255\n",
        "    \n",
        "    return out\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pscnPfCtL9BW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_step(image, itn_model):\n",
        "    with tf.GradientTape() as tape:\n",
        "        output_image = itn_model(image, training=True)\n",
        "        outputs = extractor(output_image)\n",
        "        loss = style_content_loss(outputs)\n",
        "    grads = tape.gradient(loss, itn_model.trainable_variables)\n",
        "    opt.apply_gradients(zip(grads, itn_model.trainable_variables))\n",
        "    #print(grads)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSTllpHS4HQg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init_image = keras.layers.Input(shape=[288, 288, 3])\n",
        "output_image = NST_model(init_image)\n",
        "\n",
        "ITN_model = keras.Model(init_image, output_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NroYEk4jADSw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "img_dir = '/images/'\n",
        "if not os.path.exists(img_dir):\n",
        "    os.mkdir(img_dir)\n",
        "\n",
        "!wget --quiet -P /images/ https://upload.wikimedia.org/wikipedia/commons/d/d7/Green_Sea_Turtle_grazing_seagrass.jpg\n",
        "!wget --quiet -P /images/ https://upload.wikimedia.org/wikipedia/commons/0/0a/The_Great_Wave_off_Kanagawa.jpg\n",
        "\n",
        "content_path = '/images/Green_Sea_Turtle_grazing_seagrass.jpg'\n",
        "style_path = '/images/The_Great_Wave_off_Kanagawa.jpg'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ihZGeUCAGF0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "content_layers = ['block5_conv2'] \n",
        "\n",
        "style_layers = ['block1_conv1',\n",
        "                'block2_conv1',\n",
        "                'block3_conv1', \n",
        "                'block4_conv1', \n",
        "                'block5_conv1'\n",
        "               ]\n",
        "\n",
        "num_content_layers = len(content_layers)\n",
        "num_style_layers = len(style_layers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smN5UGOZ5Fmt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "style_weight = 1e-2\n",
        "content_weight = 1e4\n",
        "total_variation_weight = 30\n",
        "iterations = 1000\n",
        "    \n",
        "style_image = load_image(style_path)\n",
        "content_image = load_image(content_path)\n",
        "init_image = content_image\n",
        "\n",
        "extractor = StyleContentModel(style_layers, content_layers)\n",
        "style_target = extractor(style_image)['style']\n",
        "content_target = extractor(content_image)['content']\n",
        "\n",
        "opt = tf.optimizers.Adam(learning_rate=0.02, beta_1=0.99, epsilon=1e-1)\n",
        "\n",
        "display_interval = 10\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for iteration in range(1, iterations+1):\n",
        "    train_step(init_image, ITN_model)\n",
        "\n",
        "    iter_time = time.time() - start_time\n",
        "    print(\"\\nIteration: {}/{} - Time: {:.4f}s\".format(iteration,\n",
        "                                                      iterations,\n",
        "                                                      iter_time))\n",
        "    imshow(output_image)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ub2E72ijP_G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}